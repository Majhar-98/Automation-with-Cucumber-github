{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk1CJxyBaSi23Gbcc3pVMk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Majhar-98/Automation-with-Cucumber-github/blob/main/MNIST_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will open a file upload dialog\n",
        "uploaded = files.upload()\n",
        "\n",
        "# This will show all uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded: {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "yjR_V1w_YREo",
        "outputId": "e0e705c9-a0ad-4642-b5c1-adb6909692e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9834a62-6992-4efc-9b99-cf1e5d19327f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9834a62-6992-4efc-9b99-cf1e5d19327f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1813608903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will open a file upload dialog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This will show all uploaded files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can import and run the uploaded module\n",
        "import mnist_experiment"
      ],
      "metadata": {
        "id": "PcuLW0lsYY_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Setup and Installations\n",
        "!pip install -q torch torchvision matplotlib tqdm seaborn\n",
        "print(\"âœ… Libraries installed!\")\n",
        "\n",
        "# %% [code]\n",
        "# @title Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ðŸ“Š GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ðŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# %% [code]\n",
        "# @title Define Configurable Neural Network\n",
        "class MNISTNet(nn.Module):\n",
        "    \"\"\"Flexible MNIST neural network with configurable architecture\"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes=[784, 256, 128, 64, 10], dropout_rate=0.2, use_batchnorm=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            layer_sizes: List of layer sizes, e.g., [784, 256, 128, 10] for 3 layers\n",
        "            dropout_rate: Dropout probability (0 to disable)\n",
        "            use_batchnorm: Whether to use batch normalization\n",
        "        \"\"\"\n",
        "        super(MNISTNet, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList() if use_batchnorm else None\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "\n",
        "        # Create layers\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
        "            if use_batchnorm and i < len(layer_sizes) - 2:  # No batch norm on output layer\n",
        "                self.batch_norms.append(nn.BatchNorm1d(layer_sizes[i + 1]))\n",
        "\n",
        "        print(f\"ðŸ“ Network created with {len(self.layers)} layers\")\n",
        "        print(f\"   Layer sizes: {layer_sizes}\")\n",
        "        print(f\"   Parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten\n",
        "\n",
        "        # Pass through hidden layers\n",
        "        for i, layer in enumerate(self.layers[:-1]):\n",
        "            x = layer(x)\n",
        "            if self.use_batchnorm:\n",
        "                x = self.batch_norms[i](x)\n",
        "            x = F.relu(x)\n",
        "            if self.dropout_rate > 0:\n",
        "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Output layer (no activation, we'll use log_softmax later)\n",
        "        x = self.layers[-1](x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# %% [code]\n",
        "# @title Load MNIST Dataset\n",
        "def load_mnist_data(batch_size=64):\n",
        "    \"\"\"Load and prepare MNIST dataset with augmentations\"\"\"\n",
        "\n",
        "    # Training augmentations\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Test transform (no augmentation)\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    print(\"ðŸ“¥ Downloading MNIST dataset...\")\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… Dataset loaded successfully!\")\n",
        "    print(f\"   Training samples: {len(train_dataset):,}\")\n",
        "    print(f\"   Test samples: {len(test_dataset):,}\")\n",
        "    print(f\"   Batch size: {batch_size}\")\n",
        "\n",
        "    # Show sample images\n",
        "    show_sample_images(train_dataset)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def show_sample_images(dataset):\n",
        "    \"\"\"Display sample images from the dataset\"\"\"\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    for i in range(10):\n",
        "        img, label = dataset[i]\n",
        "        ax = axes[i // 5, i % 5]\n",
        "        ax.imshow(img.squeeze(), cmap='gray')\n",
        "        ax.set_title(f'Label: {label}')\n",
        "        ax.axis('off')\n",
        "    plt.suptitle('Sample MNIST Images', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# %% [code]\n",
        "# @title Training Function\n",
        "def train_model(model, train_loader, test_loader, epochs=10, lr=0.001, experiment_name=\"Experiment\"):\n",
        "    \"\"\"Train the model and return metrics\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ðŸ”¬ {experiment_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define optimizer and scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "\n",
        "    # Training metrics storage\n",
        "    metrics = {\n",
        "        'train_loss': [], 'test_loss': [],\n",
        "        'train_acc': [], 'test_acc': [],\n",
        "        'learning_rates': [], 'epoch_times': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{epochs}]')\n",
        "        for batch_idx, (data, target) in enumerate(pbar):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            train_total += target.size(0)\n",
        "            train_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            if batch_idx % 100 == 0:\n",
        "                pbar.set_postfix({\n",
        "                    'Loss': f'{train_loss/(batch_idx+1):.4f}',\n",
        "                    'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
        "                })\n",
        "\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "        metrics['train_acc'].append(train_acc)\n",
        "        metrics['train_loss'].append(train_loss / len(train_loader))\n",
        "\n",
        "        # Testing phase\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                _, predicted = output.max(1)\n",
        "                test_total += target.size(0)\n",
        "                test_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        test_acc = 100. * test_correct / test_total\n",
        "        metrics['test_acc'].append(test_acc)\n",
        "        metrics['test_loss'].append(test_loss / test_total)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(metrics['test_loss'][-1])\n",
        "        metrics['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Record epoch time\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        metrics['epoch_times'].append(epoch_time)\n",
        "\n",
        "        print(f\"   Epoch {epoch+1:2d} | \"\n",
        "              f\"Train Loss: {metrics['train_loss'][-1]:.4f} | \"\n",
        "              f\"Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Test Loss: {metrics['test_loss'][-1]:.4f} | \"\n",
        "              f\"Test Acc: {test_acc:.2f}% | \"\n",
        "              f\"LR: {metrics['learning_rates'][-1]:.6f}\")\n",
        "\n",
        "    print(f\"\\nâœ… Training completed!\")\n",
        "    print(f\"   Final Train Accuracy: {metrics['train_acc'][-1]:.2f}%\")\n",
        "    print(f\"   Final Test Accuracy: {metrics['test_acc'][-1]:.2f}%\")\n",
        "    print(f\"   Average epoch time: {np.mean(metrics['epoch_times']):.2f}s\")\n",
        "\n",
        "    return metrics, model\n",
        "\n",
        "# %% [code]\n",
        "# @title Visualization Functions\n",
        "def plot_training_curves(metrics, experiment_name):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    # Plot 1: Training & Test Loss\n",
        "    ax = axes[0, 0]\n",
        "    ax.plot(metrics['train_loss'], label='Train Loss', linewidth=2)\n",
        "    ax.plot(metrics['test_loss'], label='Test Loss', linewidth=2)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title(f'{experiment_name} - Loss Curves')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Training & Test Accuracy\n",
        "    ax = axes[0, 1]\n",
        "    ax.plot(metrics['train_acc'], label='Train Accuracy', linewidth=2)\n",
        "    ax.plot(metrics['test_acc'], label='Test Accuracy', linewidth=2)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Accuracy (%)')\n",
        "    ax.set_title(f'{experiment_name} - Accuracy Curves')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 3: Learning Rate Schedule\n",
        "    ax = axes[0, 2]\n",
        "    ax.plot(metrics['learning_rates'], linewidth=2, color='purple')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Learning Rate')\n",
        "    ax.set_title(f'{experiment_name} - Learning Rate Schedule')\n",
        "    ax.set_yscale('log')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 4: Confusion Matrix (on test set)\n",
        "    # We need to compute predictions first\n",
        "    ax = axes[1, 0]\n",
        "    # We'll create a dummy confusion matrix for now\n",
        "    # In practice, you would compute this on the test set\n",
        "    ax.text(0.5, 0.5, 'Confusion Matrix\\n(Would be computed\\nwith test predictions)',\n",
        "            horizontalalignment='center', verticalalignment='center',\n",
        "            transform=ax.transAxes, fontsize=14)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Plot 5: Error Analysis\n",
        "    ax = axes[1, 1]\n",
        "    epochs = range(1, len(metrics['train_acc']) + 1)\n",
        "    ax.plot(epochs, metrics['train_acc'], 'b-', label='Train', linewidth=2)\n",
        "    ax.plot(epochs, metrics['test_acc'], 'r-', label='Test', linewidth=2)\n",
        "    ax.fill_between(epochs, metrics['train_acc'], metrics['test_acc'],\n",
        "                    alpha=0.2, color='gray')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Accuracy (%)')\n",
        "    ax.set_title(f'{experiment_name} - Train/Test Gap')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 6: Epoch Times\n",
        "    ax = axes[1, 2]\n",
        "    ax.bar(range(1, len(metrics['epoch_times']) + 1), metrics['epoch_times'])\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Time (seconds)')\n",
        "    ax.set_title(f'{experiment_name} - Epoch Training Times')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(f'Experiment: {experiment_name}', fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_predictions(model, test_loader, num_samples=12):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get some test samples\n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images[:num_samples].to(device), labels[:num_samples].to(device)\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predictions = outputs.max(1)\n",
        "        probabilities = torch.exp(outputs)\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
        "    for i in range(num_samples):\n",
        "        ax = axes[i // 4, i % 4]\n",
        "        ax.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "\n",
        "        # Color code: green if correct, red if wrong\n",
        "        color = 'green' if predictions[i] == labels[i] else 'red'\n",
        "        ax.set_title(f'Pred: {predictions[i].item()} | True: {labels[i].item()}\\n'\n",
        "                    f'Conf: {probabilities[i][predictions[i]].item():.2%}',\n",
        "                    color=color, fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle('Model Predictions on Test Samples', fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# %% [code]\n",
        "# @title Run Multiple Experiments\n",
        "print(\"ðŸš€ Starting MNIST Experiments\")\n",
        "\n",
        "# Load data once\n",
        "train_loader, test_loader = load_mnist_data(batch_size=64)\n",
        "\n",
        "# Define experiments\n",
        "experiments = [\n",
        "    {\n",
        "        'name': 'Baseline (4 layers)',\n",
        "        'model': MNISTNet(layer_sizes=[784, 256, 128, 64, 10], dropout_rate=0.0),\n",
        "        'epochs': 10,\n",
        "        'lr': 0.001\n",
        "    },\n",
        "    {\n",
        "        'name': 'Deep Network (6 layers)',\n",
        "        'model': MNISTNet(layer_sizes=[784, 512, 256, 128, 64, 32, 10], dropout_rate=0.2),\n",
        "        'epochs': 15,\n",
        "        'lr': 0.0005\n",
        "    },\n",
        "    {\n",
        "        'name': 'Shallow Network (3 layers)',\n",
        "        'model': MNISTNet(layer_sizes=[784, 128, 64, 10], dropout_rate=0.0),\n",
        "        'epochs': 10,\n",
        "        'lr': 0.001\n",
        "    },\n",
        "    {\n",
        "        'name': 'High Learning Rate',\n",
        "        'model': MNISTNet(layer_sizes=[784, 256, 128, 64, 10], dropout_rate=0.2),\n",
        "        'epochs': 10,\n",
        "        'lr': 0.01  # High learning rate\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run all experiments\n",
        "all_results = []\n",
        "for exp in experiments:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ðŸƒ Starting: {exp['name']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    metrics, trained_model = train_model(\n",
        "        model=exp['model'],\n",
        "        train_loader=train_loader,\n",
        "        test_loader=test_loader,\n",
        "        epochs=exp['epochs'],\n",
        "        lr=exp['lr'],\n",
        "        experiment_name=exp['name']\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    all_results.append({\n",
        "        'name': exp['name'],\n",
        "        'metrics': metrics,\n",
        "        'model': trained_model,\n",
        "        'final_test_acc': metrics['test_acc'][-1],\n",
        "        'final_train_acc': metrics['train_acc'][-1]\n",
        "    })\n",
        "\n",
        "    # Plot curves for this experiment\n",
        "    plot_training_curves(metrics, exp['name'])\n",
        "\n",
        "    # Show sample predictions\n",
        "    plot_predictions(trained_model, test_loader)\n",
        "\n",
        "# %% [code]\n",
        "# @title Compare All Experiments\n",
        "print(\"\\nðŸ“Š COMPARISON OF ALL EXPERIMENTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = []\n",
        "for result in all_results:\n",
        "    comparison_data.append({\n",
        "        'Experiment': result['name'],\n",
        "        'Final Train Acc': f\"{result['final_train_acc']:.2f}%\",\n",
        "        'Final Test Acc': f\"{result['final_test_acc']:.2f}%\",\n",
        "        'Test Loss': f\"{result['metrics']['test_loss'][-1]:.4f}\",\n",
        "        'Avg Epoch Time': f\"{np.mean(result['metrics']['epoch_times']):.2f}s\",\n",
        "        'Best Epoch': np.argmax(result['metrics']['test_acc']) + 1\n",
        "    })\n",
        "\n",
        "# Display as DataFrame\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Visual comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot 1: Final Test Accuracy Comparison\n",
        "ax = axes[0]\n",
        "experiment_names = [r['name'] for r in all_results]\n",
        "test_accs = [r['final_test_acc'] for r in all_results]\n",
        "train_accs = [r['final_train_acc'] for r in all_results]\n",
        "\n",
        "x = np.arange(len(experiment_names))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(x - width/2, train_accs, width, label='Train', color='skyblue', alpha=0.8)\n",
        "ax.bar(x + width/2, test_accs, width, label='Test', color='lightcoral', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Experiment')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Final Accuracy Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(experiment_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for i, (train, test) in enumerate(zip(train_accs, test_accs)):\n",
        "    ax.text(i - width/2, train + 0.5, f'{train:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "    ax.text(i + width/2, test + 0.5, f'{test:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Plot 2: Test Accuracy Over Time\n",
        "ax = axes[1]\n",
        "for i, result in enumerate(all_results):\n",
        "    ax.plot(result['metrics']['test_acc'], label=result['name'], linewidth=2)\n",
        "\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Test Accuracy (%)')\n",
        "ax.set_title('Test Accuracy Progress')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Experiment Comparison', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# %% [code]\n",
        "# @title Learning Rate Finder Experiment\n",
        "print(\"\\nðŸŽ¯ LEARNING RATE FINDER EXPERIMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try different learning rates\n",
        "learning_rates = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
        "lr_results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nTesting LR = {lr}\")\n",
        "    model = MNISTNet(layer_sizes=[784, 256, 128, 64, 10], dropout_rate=0.2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Quick test: train for 2 epochs\n",
        "    model.train()\n",
        "    for epoch in range(2):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            if batch_idx > 50:  # Only use 50 batches for quick test\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    lr_results.append(acc)\n",
        "    print(f\"   Test Accuracy after 2 epochs: {acc:.2f}%\")\n",
        "\n",
        "# Plot LR vs Accuracy\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.semilogx(learning_rates, lr_results, 'o-', linewidth=2, markersize=8, color='purple')\n",
        "ax.set_xlabel('Learning Rate (log scale)')\n",
        "ax.set_ylabel('Test Accuracy (%)')\n",
        "ax.set_title('Learning Rate vs Accuracy (2 epochs)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight best LR\n",
        "best_idx = np.argmax(lr_results)\n",
        "ax.axvline(x=learning_rates[best_idx], color='red', linestyle='--', alpha=0.5)\n",
        "ax.annotate(f'Best LR: {learning_rates[best_idx]}\\nAcc: {lr_results[best_idx]:.2f}%',\n",
        "            xy=(learning_rates[best_idx], lr_results[best_idx]),\n",
        "            xytext=(10, 10), textcoords='offset points',\n",
        "            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# %% [code]\n",
        "# @title Save and Download Results\n",
        "print(\"\\nðŸ’¾ Saving results...\")\n",
        "\n",
        "# Create summary report\n",
        "report = f\"\"\"\n",
        "MNIST Experiments Summary Report\n",
        "{'='*50}\n",
        "Generated: {time.ctime()}\n",
        "Device: {device}\n",
        "Total experiments: {len(all_results)}\n",
        "\n",
        "{'='*50}\n",
        "\"\"\"\n",
        "\n",
        "for result in all_results:\n",
        "    report += f\"\"\"\n",
        "Experiment: {result['name']}\n",
        "  Final Train Accuracy: {result['final_train_acc']:.2f}%\n",
        "  Final Test Accuracy: {result['final_test_acc']:.2f}%\n",
        "  Best epoch: {np.argmax(result['metrics']['test_acc']) + 1}\n",
        "  Average epoch time: {np.mean(result['metrics']['epoch_times']):.2f}s\n",
        "  Parameters: {sum(p.numel() for p in result['model'].parameters()):,}\n",
        "  {'-'*50}\n",
        "\"\"\"\n",
        "\n",
        "report += f\"\"\"\n",
        "{'='*50}\n",
        "Best experiment: {max(all_results, key=lambda x: x['final_test_acc'])['name']}\n",
        "Best test accuracy: {max(r['final_test_acc'] for r in all_results):.2f}%\n",
        "\"\"\"\n",
        "\n",
        "# Save report to file\n",
        "with open('experiment_report.txt', 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "# Save models (just the best one)\n",
        "best_model = max(all_results, key=lambda x: x['final_test_acc'])['model']\n",
        "torch.save(best_model.state_dict(), 'best_mnist_model.pth')\n",
        "\n",
        "print(\"âœ… Results saved!\")\n",
        "print(\"\\nðŸ“„ Report saved as: experiment_report.txt\")\n",
        "print(\"ðŸ¤– Best model saved as: best_mnist_model.pth\")\n",
        "\n",
        "# Optionally download files\n",
        "print(\"\\nðŸ“¥ To download files, run:\")\n",
        "print(\"from google.colab import files\")\n",
        "print(\"files.download('experiment_report.txt')\")\n",
        "print(\"files.download('best_mnist_model.pth')\")\n",
        "\n",
        "# %% [code]\n",
        "print(\"\\n\" + \"ðŸŽ‰\" * 30)\n",
        "print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"ðŸŽ‰\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M1hKY6MgYaFk",
        "outputId": "ccaf60d7-599e-43e1-fdae-38cc3c56ab1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Libraries installed!\n",
            "ðŸš€ Using device: cpu\n",
            "ðŸš€ Starting MNIST Experiments\n",
            "ðŸ“¥ Downloading MNIST dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 22.6MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 614kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 5.58MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.99MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset loaded successfully!\n",
            "   Training samples: 60,000\n",
            "   Test samples: 10,000\n",
            "   Batch size: 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Network created with 4 layers\n",
            "   Layer sizes: [784, 256, 128, 64, 10]\n",
            "   Parameters: 243,658\n",
            "ðŸ“ Network created with 6 layers\n",
            "   Layer sizes: [784, 512, 256, 128, 64, 32, 10]\n",
            "   Parameters: 578,794\n",
            "ðŸ“ Network created with 3 layers\n",
            "   Layer sizes: [784, 128, 64, 10]\n",
            "   Parameters: 109,770\n",
            "ðŸ“ Network created with 4 layers\n",
            "   Layer sizes: [784, 256, 128, 64, 10]\n",
            "   Parameters: 243,658\n",
            "\n",
            "======================================================================\n",
            "ðŸƒ Starting: Baseline (4 layers)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "ðŸ”¬ Baseline (4 layers)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:29<00:00, 31.61it/s, Loss=0.4164, Acc=88.03%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  1 | Train Loss: 0.4088 | Train Acc: 88.20% | Test Loss: 0.1356 | Test Acc: 95.77% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:28<00:00, 32.86it/s, Loss=0.1837, Acc=94.27%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  2 | Train Loss: 0.1834 | Train Acc: 94.27% | Test Loss: 0.0776 | Test Acc: 97.46% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:29<00:00, 31.53it/s, Loss=0.1497, Acc=95.24%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  3 | Train Loss: 0.1501 | Train Acc: 95.23% | Test Loss: 0.0715 | Test Acc: 97.71% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:29<00:00, 32.26it/s, Loss=0.1363, Acc=95.60%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  4 | Train Loss: 0.1353 | Train Acc: 95.64% | Test Loss: 0.0611 | Test Acc: 97.91% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:28<00:00, 32.87it/s, Loss=0.1222, Acc=96.14%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  5 | Train Loss: 0.1217 | Train Acc: 96.15% | Test Loss: 0.0581 | Test Acc: 98.15% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:29<00:00, 31.57it/s, Loss=0.1142, Acc=96.35%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  6 | Train Loss: 0.1143 | Train Acc: 96.35% | Test Loss: 0.0542 | Test Acc: 98.11% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:29<00:00, 31.96it/s, Loss=0.1045, Acc=96.70%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch  7 | Train Loss: 0.1042 | Train Acc: 96.72% | Test Loss: 0.0564 | Test Acc: 98.20% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [8/10]:   0%|          | 0/938 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}